**What are the various datetime types in hive?**
- Date 
- TIME 
- TIMESTAMP (java.sql.Timestamp) 

# Timestamp Issue
For timestamp column the incoming data is assumed to UTC and hive converts to servers timezone when reading it (and does not provide the raw data as it is )

Hive stores timestamp as java.sql.Timestamp which stores values as offset from 1970    
Thus, hive TIMESTAMP has no timezone: It represents an instant (usually stored/handled as UTC) but displays per session TZ.

- If incoming data is in NY timezone (or any other non UTC) timezone this would cause issue. Since UTC assumption is invalid.
- Each reader will gets its own local time shifted value when reading (instead of raw data)

## 1. How Hive stores and interprets `TIMESTAMP`

* **Storage**: Hive‚Äôs `TIMESTAMP` type is meant to represent an **absolute instant in time**. Internally (ORC/Parquet), most engines write it normalized to **UTC**, even if you load data in another timezone.
* **Display**: When you `SELECT` from Hive, it renders that instant according to the **session time zone** (by default, the HiveServer2 JVM‚Äôs system timezone).
* **Result**: The same stored value will *print differently* depending on who queries it, since the rendering depends on the reader‚Äôs session TZ.

---

## 2. Why ‚Äúraw value‚Äù is lost

* When you ingest a bare string like `2023-01-01 04:06:19.323` into a `TIMESTAMP` column:

  * Hive parses it as if it were **in the current session time zone** (e.g. EST).
  * It immediately converts that to a UTC instant.
  * From then on, you‚Äôve lost the knowledge that the original string was ‚Äú04:06 EST‚Äù. You only have the instant.
* When another reader connects (say in Singapore), Hive takes that instant and shows it in *their* session time zone. They‚Äôll see `2023-01-01 17:06:19.323`, not the raw text.

So yes ‚Äî you don‚Äôt get back what you ingested. You get a ‚Äúshifted‚Äù rendering.

---

## 3. Why this bites people

1. **Analyst expectation**: People often expect `SELECT *` to show exactly what was loaded from CSV. But TIMESTAMP silently normalizes.
   ‚Üí The New York analyst sees `04:06`, the Singapore analyst sees `17:06`.
2. **Partitioning**: If you partition by date derived from `TIMESTAMP`, users in different zones may think rows belong to ‚Äúwrong‚Äù days.
3. **ETL cross-loads**: If Spark writes to Parquet in UTC but Hive reads with EST session, times can look shifted by several hours.
4. **Debugging hell**: CSV backups, logs, or audits show ‚Äúraw‚Äù values, but Hive queries don‚Äôt match unless you force UTC rendering.

---

## 4. If you want the raw value

You need to avoid automatic interpretation:

* **Option A: Store as `STRING`**
  Keep the original text exactly as-is. Add a parallel `TIMESTAMP_UTC` column for normalized use.
* **Option B: Store both**
  One column for raw string (or ‚Äúlocal wall clock‚Äù), one column converted to UTC for analytics.
* **Option C: Use `from_unixtime` / `to_utc_timestamp` explicitly**
  Parse with explicit zone conversion so it‚Äôs clear in ETL what the stored UTC instant should be.

---

## 5. Golden rule

üëâ Hive `TIMESTAMP` is *not* a ‚Äúraw local datetime‚Äù. It is ‚Äúan instant normalized to UTC, shown in your session TZ‚Äù.
If you need the literal string or the local wall time semantics (e.g. ‚Äúthe shop opened at 9am local‚Äù), you **must store it separately** (e.g., as STRING + TZ column).





